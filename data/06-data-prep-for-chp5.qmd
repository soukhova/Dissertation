Libraries:
```{r}
library(sf)
library(ggplot2)
library(dplyr)
library(osmextract)
library(tidyr)
library(data.table)
library(fst)
```

Load origin data:
```{r}
load(file="./TO_census_21_DB.rda")
load(file="./TO_census_21_DA.rda")
```

Filter only the toronto DBs, and add info about the neighbourhoods (tie in by DA ID)
```{r}
TO_census_21_DB <- TO_census_21_DB |> filter(CSD_UID == "3520005")

TO_census_21_DB <- TO_census_21_DB |> left_join(neigh_CT_DA |> select(-c("X", "GeoUID_CT")),
                                                by=(c("DA_UID"="GeoUID_DA")))
```

Get waterbodies?
```{r}
# Get large-scale lakes
lakes <- ne_download(scale = 10, type = "lakes", category = "physical", returnclass = "sf")
lake_ontario <- lakes[lakes$name == "Lake Ontario", ]
toronto_bbox <- st_bbox(TO_census_21_DB) 
```

# Travel impedance functions

The exponential and cutoff functions to be used for walk mode:
```{r}
c_ij <- seq(0, 120, by = 1)

decay_func <- function(c, beta) {
  exp(-beta * c)
}

cutoff_func <- function(c, threshold) {
  ifelse(c <= threshold, 1, 0)
}
```

Load destinations and origins:
```{r}
load(file="./parkland.rda")
#load(file="./parkland_edge_and_centroid_entrance_points.rda")
parkland_grouped <- parkland |> group_by(P_ID)|>
  summarise(count_entrances_P_ID = mean(count_entrances_P_ID),
            area_ha = sum(area_ha)) |>
  mutate(park_size = case_when(area_ha < 0.5 ~ "Parkette",
                               area_ha >= 0.5 & area_ha < 1.5 ~ "Small Park",
                               area_ha >= 1.5 & area_ha < 3.0 ~ "Medium Park",
                               area_ha >= 3.0 & area_ha < 5.0 ~ "Large Park",
                               area_ha >= 5.0 & area_ha < 8.0 ~ "City Park",
                               area_ha >= 8.0 ~ "Legacy Park"))

DB_Centroids <- st_read("./DB_Centroids/DB_Centroids.shp")
DB_Centroids_pop <- DB_Centroids |> st_drop_geometry() |> dplyr::select(c("DBUID_txt", "POP2021")) |> rename("from_id" = "DBUID_txt")
#load("./TO_census_21_DB.rda")
```


# Creating the OD matrices with origin and destination weights.

Let's find the shortest travel time from each origin to each destination. AND! Add the mode share proportions to each DB. 

WALK (it's already created)
```{r, eval=FALSE}
load(file="./ttm/ttm_WALK_foranalysis.rda")
ttm_WALK_shortest_by_P <- ttm_WALK_foranalysis |> 
  group_by(from_id, P_ID) |> #unique origin id and unique park ID
  summarise(P_ID = mean(P_ID),
            min_travel_time_p50 = min(travel_time_p50),
            travel_time_p50_SD = sd(travel_time_p50),
            entrance_count = n(),
            entrance_type = first(entrance_type))
rm(ttm_WALK_foranalysis)

ttm_WALK_shortest_by_P <- ttm_WALK_shortest_by_P |>
  dplyr::select(c("from_id", "P_ID", "min_travel_time_p50")) |> 
  left_join(parkland_grouped |> st_drop_geometry() |> 
              dplyr::select(c("P_ID","area_ha", "park_size")),
            by="P_ID") |>
  left_join(DB_Centroids_pop, by = "from_id")

#adding impedance
cutoff_func <- function(c, threshold) {
  ifelse(c <= threshold, 1, 0)
}

OD_WALK <- ttm_WALK_shortest_by_P |> 
  mutate(
    f = case_when(park_size == "Parkette" ~ cutoff_func(min_travel_time_p50, 15),
                 park_size == "Small Park" ~ cutoff_func(min_travel_time_p50, 15),
                 park_size == "Medium Park" ~ cutoff_func(min_travel_time_p50, 15),
                 park_size %in% c("Large Park", "City Park", "Legacy Park") ~ cutoff_func(min_travel_time_p50, 15),
      TRUE ~ 0))
rm(ttm_WALK_shortest_by_P)
save(OD_WALK ,file="./OD_WALK.rda")
rm(OD_WALK)
```

CYCLING:
```{r, eval=FALSE}
load(file="./ttm/ttm_BICYCLE_foranalysis.rda")
ttm_BICYCLE_shortest_by_P <- ttm_BICYCLE_foranalysis |> 
  group_by(from_id, P_ID) |> #unique origin id and unique park ID
  summarise(P_ID = mean(P_ID),
            min_travel_time_p50 = min(travel_time_p50),
            travel_time_p50_SD = sd(travel_time_p50),
            entrance_count = n(),
            entrance_type = first(entrance_type))
rm(ttm_BICYCLE_foranalysis)

ttm_BICYCLE_shortest_by_P <- ttm_BICYCLE_shortest_by_P |>
  dplyr::select(c("from_id", "P_ID", "min_travel_time_p50")) |> 
  left_join(parkland_grouped |> st_drop_geometry() |> 
              dplyr::select(c("P_ID","area_ha", "park_size")),
            by="P_ID") |>
  left_join(DB_Centroids_pop, by = "from_id")

#adding impedance
cutoff_func <- function(c, threshold) {
  ifelse(c <= threshold, 1, 0)
}

OD_BICYCLE <- ttm_BICYCLE_shortest_by_P |> 
  mutate(
    f = case_when(park_size == "Parkette" ~ cutoff_func(min_travel_time_p50, 15),
                 park_size == "Small Park" ~ cutoff_func(min_travel_time_p50, 15),
                 park_size == "Medium Park" ~ cutoff_func(min_travel_time_p50, 15),
                 park_size %in% c("Large Park", "City Park", "Legacy Park") ~ cutoff_func(min_travel_time_p50, 15),
      TRUE ~ 0))
rm(ttm_BICYCLE_shortest_by_P)
save(OD_BICYCLE ,file="./OD_BICYCLE.rda")
rm(OD_BICYCLE)
```


TRANSIT:
```{r, eval=FALSE}
load(file="./ttm/ttm_TRANSIT_foranalysis.rda")
ttm_TRANSIT_shortest_by_P <- ttm_TRANSIT_foranalysis |> 
  group_by(from_id, P_ID) |> #unique origin id and unique park ID
  summarise(P_ID = mean(P_ID),
            min_travel_time_p50 = min(travel_time_p50),
            travel_time_p50_SD = sd(travel_time_p50),
            entrance_count = n(),
            entrance_type = first(entrance_type))
rm(ttm_TRANSIT_foranalysis)

ttm_TRANSIT_shortest_by_P <- ttm_TRANSIT_shortest_by_P |>
  dplyr::select(c("from_id", "P_ID", "min_travel_time_p50")) |> 
  left_join(parkland_grouped |> st_drop_geometry() |> 
              dplyr::select(c("P_ID","area_ha", "park_size")),
            by="P_ID") |>
  left_join(DB_Centroids_pop, by = "from_id")

OD_TRANSIT <- ttm_TRANSIT_shortest_by_P |> 
  mutate(
    f = decay_func(min_travel_time_p50, 0.02))
rm(ttm_TRANSIT_shortest_by_P)
save(OD_TRANSIT ,file="./OD_TRANSIT.rda")
rm(OD_TRANSIT)
```

CAR:
```{r, eval=FALSE}
load(file="./ttm/ttm_CAR_foranalysis.rda")
ttm_CAR_shortest_by_P <- ttm_CAR_foranalysis |> 
  group_by(from_id, P_ID) |> #unique origin id and unique park ID
  summarise(min_travel_time_p50 = min(travel_time_p50))
rm(ttm_CAR_foranalysis)

ttm_CAR_shortest_by_P <- ttm_CAR_shortest_by_P |>
  dplyr::select(c("from_id", "P_ID", "min_travel_time_p50")) |> 
  left_join(parkland_grouped |> st_drop_geometry() |> 
              dplyr::select(c("P_ID","area_ha", "park_size")),
            by="P_ID") |>
  left_join(DB_Centroids_pop, by = "from_id")

OD_CAR <- ttm_CAR_shortest_by_P |> 
  mutate(f = decay_func(min_travel_time_p50, 0.04))
rm(ttm_CAR_shortest_by_P)
save(OD_CAR ,file="./OD_CAR.rda")
rm(OD_CAR)
```

Load:
```{r}
load(file="./OD_WALK.rda")
load(file="./OD_BICYCLE.rda")
load(file="./OD_TRANSIT.rda")
load(file="./OD_CAR.rda")
```

Add TTS and link their modal splits to each DB (based on matching TAZ). First load in the tts, then load in the TAZ zoning system and establish a list of DB IDs for each TAZ:
```{r, eval=FALSE}
load(file="TTS-trips/od_leisure_transit.rda")
load(file="TTS-trips/od_leisure_car.rda")
load(file="TTS-trips/od_leisure_walk.rda")
load(file="TTS-trips/od_leisure_cycling.rda")

library(TTS2016R)

ggh_taz <- TTS2016R::ggh_taz |> filter(REGION == 1) #only TORONTO!
ggh_taz <- st_transform(ggh_taz, st_crs(TO_census_21_DB))

DB_gta06_list <- st_join(TO_census_21_DB, ggh_taz, join = st_intersects)|>
  st_drop_geometry()|>
  select(DB_UID, GTA06)

car_trips <- od_leisure_car|> group_by(GTA06 = Origin)|> summarise(car_trips = sum(Trips))
walk_trips <- od_leisure_walk|> group_by(GTA06 = Origin)|> summarise(walk_trips = sum(Trips))
bike_trips <- od_leisure_cycling|> group_by(GTA06 = Origin)|> summarise(cycle_trips = sum(Trips))
transit_trips <- od_leisure_transit|> group_by(GTA06 = Origin)|> summarise(transit_trips = sum(Trips))

gta06_trips <- reduce(
  list(car_trips, walk_trips, bike_trips, transit_trips),
  full_join,
  by = "GTA06"
)|> mutate(across(everything(), ~replace_na(., 0)))

DB_gta06_list <- DB_gta06_list|>
  left_join(gta06_trips, by = "GTA06")

DB_gta06_list_modesplit <- DB_gta06_list|>
  group_by(DB_UID)|>
  summarise(
    car_trips = mean(car_trips, na.rm=T),
    walk_trips = mean(walk_trips, na.rm=T),
    cycle_trips = mean(cycle_trips, na.rm=T),
    transit_trips = mean(transit_trips, na.rm=T),
    total_trips = car_trips + walk_trips + cycle_trips + transit_trips,
    prop_car = if_else(total_trips > 0, car_trips / total_trips, 0),
    prop_walk = if_else(total_trips > 0, walk_trips / total_trips, 0),
    prop_cycle = if_else(total_trips > 0, cycle_trips / total_trips, 0),
    prop_transit = if_else(total_trips > 0, transit_trips / total_trips, 0)
  )

#for reporting in the chapter:
sum(gta06_trips$transit_trips, gta06_trips$cycle_trips, gta06_trips$walk_trips, gta06_trips$car_trips)
save(DB_gta06_list_modesplit, file="./TTS-trips/DB_gta06_list_modesplit.rda")
```

```{r}
load(file="./TTS-trips/DB_gta06_list_modesplit.rda")
summary(DB_gta06_list_modesplit)
```
see, we have 131 DBs with NA trips. lets backfill it.

```{r}
DB_with_trips <- TO_census_21_DB|>
  st_drop_geometry()|>
  select(c("DB_UID", "DA_UID")) |>
  left_join(DB_gta06_list_modesplit, by = c("DB_UID"="Region Name"))

# Average trip + prop data per DA_UID
da_level_averages <- DB_with_trips|>
  group_by(DA_UID)|>
  summarise(
    car_trips = mean(car_trips, na.rm = TRUE),
    walk_trips = mean(walk_trips, na.rm = TRUE),
    cycle_trips = mean(cycle_trips, na.rm = TRUE),
    transit_trips = mean(transit_trips, na.rm = TRUE),
    total_trips = mean(total_trips, na.rm = TRUE),
    prop_car = mean(prop_car, na.rm = TRUE),
    prop_walk = mean(prop_walk, na.rm = TRUE),
    prop_cycle = mean(prop_cycle, na.rm = TRUE),
    prop_transit = mean(prop_transit, na.rm = TRUE)
  )

TO_census_21_DB <- TO_census_21_DB|>
  left_join(DB_gta06_list_modesplit, by = c("DB_UID"="Region Name"))|>
  left_join(da_level_averages, by = "DA_UID", suffix = c("", "_da"))

#fill in the NAs
TO_census_21_DB <- TO_census_21_DB|>
  mutate(
    car_trips = if_else(is.na(car_trips), car_trips_da, car_trips),
    walk_trips = if_else(is.na(walk_trips), walk_trips_da, walk_trips),
    cycle_trips = if_else(is.na(cycle_trips), cycle_trips_da, cycle_trips),
    transit_trips = if_else(is.na(transit_trips), transit_trips_da, transit_trips),
    total_trips = if_else(is.na(total_trips), total_trips_da, total_trips),
    prop_car = if_else(is.na(prop_car), prop_car_da, prop_car),
    prop_walk = if_else(is.na(prop_walk), prop_walk_da, prop_walk),
    prop_cycle = if_else(is.na(prop_cycle), prop_cycle_da, prop_cycle),
    prop_transit = if_else(is.na(prop_transit), prop_transit_da, prop_transit)
  )|>
  select(-ends_with("_da"))  # Clean up DA-level temp columns
```

```{r}
DB_with_trips <- TO_census_21_DB|>
  st_drop_geometry()|>
  select(DB_UID, CT_UID, car_trips, walk_trips, cycle_trips, transit_trips, total_trips, 
         prop_car, prop_walk, prop_cycle, prop_transit)

# Compute averages at CT level
ct_level_averages <- DB_with_trips|>
  group_by(CT_UID)|>
  summarise(
    car_trips_ct = mean(car_trips, na.rm = TRUE),
    walk_trips_ct = mean(walk_trips, na.rm = TRUE),
    cycle_trips_ct = mean(cycle_trips, na.rm = TRUE),
    transit_trips_ct = mean(transit_trips, na.rm = TRUE),
    total_trips_ct = mean(total_trips, na.rm = TRUE),
    prop_car_ct = mean(prop_car, na.rm = TRUE),
    prop_walk_ct = mean(prop_walk, na.rm = TRUE),
    prop_cycle_ct = mean(prop_cycle, na.rm = TRUE),
    prop_transit_ct = mean(prop_transit, na.rm = TRUE)
  )

TO_census_21_DB <- TO_census_21_DB|>
  left_join(ct_level_averages, by = "CT_UID")

TO_census_21_DB <- TO_census_21_DB|>
  mutate(
    car_trips = if_else(is.na(car_trips), car_trips_ct, car_trips),
    walk_trips = if_else(is.na(walk_trips), walk_trips_ct, walk_trips),
    cycle_trips = if_else(is.na(cycle_trips), cycle_trips_ct, cycle_trips),
    transit_trips = if_else(is.na(transit_trips), transit_trips_ct, transit_trips),
    total_trips = if_else(is.na(total_trips), total_trips_ct, total_trips),
    prop_car = if_else(is.na(prop_car), prop_car_ct, prop_car),
    prop_walk = if_else(is.na(prop_walk), prop_walk_ct, prop_walk),
    prop_cycle = if_else(is.na(prop_cycle), prop_cycle_ct, prop_cycle),
    prop_transit = if_else(is.na(prop_transit), prop_transit_ct, prop_transit)
  )|>
  select(-ends_with("_ct"))  # Remove temporary CT-level columns
```

```{r}
summary(TO_census_21_DB)
```

Nice! So modal proportions come from TAZ information tied to DBs. However, some DBs are not assigned any trips -- likely as those TAZs do not have leisure trips at all. But, all DBs should have complete modal trip data. So these NAs are filled in via: DB-level calculations (first), then remaining DBs take averages from the DA level (second), and lastly the remaining DBs get average values at the CT level. 

Add this list to DB object, and create a plot of 4 maps showing proportion of mode type on the same scale. For chp 3:
```{r, eval=FALSE}
plot_data <- TO_census_21_DB|>
  select(DB_UID, geometry, prop_car, prop_walk, prop_cycle, prop_transit)|>
  pivot_longer(
    cols = starts_with("prop_"),
    names_to = "mode",
    values_to = "proportion"
  )|>
  mutate(
    mode = case_when(
      mode == "prop_car" ~ "Car",
      mode == "prop_walk" ~ "Walk",
      mode == "prop_cycle" ~ "Bicycle",
      mode == "prop_transit" ~ "Transit"
    )
  )


mode_split_eachDB_plots <- ggplot() +
  geom_sf(data = lake_ontario, fill="lightblue", col=NA, size = 0.3) +
  geom_sf(data = plot_data, 
          aes(fill = proportion), color = NA) +
  scale_fill_viridis_c(limits = c(0, 1), option = "C", na.value = "grey90") +
    geom_sf(data = TO_boundary, col ="grey30", size = 6, fill = NA) +
  coord_sf(xlim = c(toronto_bbox["xmin"], toronto_bbox["xmax"]), 
           ylim = c(toronto_bbox["ymin"], toronto_bbox["ymax"]), 
           expand = FALSE) +
  facet_wrap(~mode, ncol = 2) +
  labs(fill = "Proportion") +
  theme_void() +
  theme(strip.text = element_text(size = 12),
        legend.position = "bottom") +
  annotation_scale(location = "br", width_hint = 0.2) +   #
  annotation_north_arrow(location = "tl", which_north = "true", 
                         height = unit(1, "cm"), width = unit(1, "cm"))

mode_split_eachDB_plots
ggsave("./figures/chp3-mode_split_eachDB_plots.png", width = 10, height = 10, dpi = 300)
```

## 1. calc the multimodal total parkland ha and population that goes into constrained accessibility
First, calc the total parkland area  & sum of parkland that enters the accessibility calc.

Filter out trips that don't happen (f=0) and where pop is 0, as people aren't demanding (or acting on supply) there.
```{r}
OD_WALK <- OD_WALK |> filter(f != 0 & POP2021 != 0)
OD_BICYCLE <- OD_BICYCLE |> filter(f != 0 & POP2021 != 0)
OD_TRANSIT <- OD_TRANSIT |> filter(f != 0 & POP2021 != 0)
OD_CAR <- OD_CAR |> filter(f != 0 & POP2021 != 0) 
```

Calc the sum of total parkland, and by each mode that is accessed:
```{r}
sum_parks_TOTAL <- parkland_grouped |> st_drop_geometry() |> pull(area_ha) |> sum()

sum_OD_WALK_parks_y <- OD_WALK |> 
  group_by(P_ID) |> summarise(sum_D_j = first(area_ha),
                              park_size = first(park_size))

sum_OD_BICYCLE_parks_y <- OD_BICYCLE |> 
  group_by(P_ID) |> summarise(sum_D_j = first(area_ha),
                              park_size = first(park_size))

sum_OD_TRANSIT_parks_y <- OD_TRANSIT |>
  group_by(P_ID) |> summarise(sum_D_j = first(area_ha),
                              park_size = first(park_size))

sum_OD_CAR_parks_y <- OD_CAR |>
  group_by(P_ID) |> summarise(sum_D_j = first(area_ha),
                              park_size = first(park_size)) 

sum_OD_WALK_parks_TOTAL <- sum_OD_WALK_parks_y |> pull(sum_D_j) |> sum()
sum_OD_BICYCLE_parks_TOTAL <- sum_OD_BICYCLE_parks_y |> pull(sum_D_j) |> sum()
sum_OD_TRANSIT_parks_TOTAL <- sum_OD_TRANSIT_parks_y |> pull(sum_D_j) |> sum()
sum_OD_CAR_parks_TOTAL <- sum_OD_CAR_parks_y |> pull(sum_D_j) |> sum()
```

Visually inspect: the sum of total parks vs. what goes into the access measure
```{r}
sum_parks_TOTAL #the total amount of parks, 8037.547

sum_OD_WALK_parks_TOTAL  #7592.858
sum_OD_BICYCLE_parks_TOTAL #7962.669
sum_OD_TRANSIT_parks_TOTAL #7864.192
sum_OD_CAR_parks_TOTAL #7948.76
```

Which is, the following park area that is NOT included. For active modes, it is the parkland space near the shoreline in the east (bluffs) that are hard to reach / impossible by transit/cycling according to the road network. For car, the toronto island parks are not reachable as no car is allowed there: 
```{r}
parkland |> st_drop_geometry() |> left_join(sum_OD_WALK_parks_y, by= "P_ID")  |> filter(is.na(sum_D_j))
parkland |> st_drop_geometry() |> left_join(sum_OD_BICYCLE_parks_y, by= "P_ID")  |> filter(is.na(sum_D_j))
parkland |> st_drop_geometry() |> left_join(sum_OD_TRANSIT_parks_y, by= "P_ID")  |> filter(is.na(sum_D_j))
parkland |> st_drop_geometry() |> left_join(sum_OD_CAR_parks_y, by= "P_ID")  |> filter(is.na(sum_D_j))
```

Interesting--- it appears that these excluded parks are not all common across all modes-- maybe together, all parks can be reached hence total parkland area goes into the equation?
```{r}
all_pids <- bind_rows(
  OD_WALK  |> select(P_ID, area_ha),
  OD_BICYCLE |> select(P_ID, area_ha),
  OD_TRANSIT |> select(P_ID, area_ha),
  OD_CAR  |> select(P_ID, area_ha)
)

unique_parks <- all_pids %>%
  group_by(P_ID) %>%
  summarise(area_ha = first(area_ha), .groups = "drop")

sum_allmodes_PARKLAND <- sum(unique_parks$area_ha, na.rm = TRUE) #8037.547 hectres
sum_allmodes_PARKLAND
```
Indeed! it appears the total parkland sum does enter the equation. 8037.547. Use this as the numerator for TOTAL-- and this is our expected sum of opportunities for Singly Constrained opp-constrained as well.

Lets also calc the sum of population that enters the accessibility calc vs. the total population. This is for market potential.
```{r}
sum_TOTAL_population <- DB_Centroids_pop$POP2021 |> sum()
```

```{r}
#add prop of the mode to OD of the mode
OD_WALK <- OD_WALK |> left_join(TO_census_21_DB |> st_drop_geometry() |>
                                  select(c("DB_UID", "prop_walk")), 
                                by=c("from_id" = "DB_UID"))

OD_BICYCLE <- OD_BICYCLE |> left_join(TO_census_21_DB |> st_drop_geometry() |>
                                        select(c("DB_UID", "prop_cycle")), 
                                by=c("from_id" = "DB_UID"))
OD_TRANSIT <- OD_TRANSIT |> left_join(TO_census_21_DB |> st_drop_geometry() |>
                                        select(c("DB_UID", "prop_transit")), 
                                by=c("from_id" = "DB_UID"))
OD_CAR <- OD_CAR |> left_join(TO_census_21_DB |> st_drop_geometry() |>
                                select(c("DB_UID", "prop_car")), 
                                by=c("from_id" = "DB_UID"))
```

Let's create a megatable with the correct proportions based on trips that remain:
```{r}
walk_df <- OD_WALK |> 
  select(from_id, P_ID, f, prop = prop_walk) %>%
  mutate(mode = "Walk") |> filter(prop != 0) 

car_df <- OD_CAR |> 
  select(from_id, P_ID, f, prop = prop_car) %>%
  mutate(mode = "Car") |> filter(prop != 0) 

transit_df <- OD_TRANSIT |> 
  select(from_id, P_ID, f, prop = prop_transit) %>%
  mutate(mode = "Transit") |> filter(prop != 0) 

cycle_df <- OD_BICYCLE |> 
  select(from_id, P_ID, f, prop = prop_cycle) %>%
  mutate(mode = "Bicycle") |> filter(prop != 0) 
```

Using data.table, much faster:
```{r}
OD_allmodes <- bind_rows(walk_df, car_df, transit_df, cycle_df) |> as.data.table()
```

Let's join 2 extra columns to this long OD table. the parkland area by dest, and the population by orig. We'll also use dt for speed.
```{r}
TO_census_21_DB_dt <- as.data.table(TO_census_21_DB |> st_drop_geometry()|> select(c("DB_UID","Population")))
parkland_grouped_dt <- as.data.table(parkland_grouped|> st_drop_geometry()|> select(c("P_ID","area_ha")))

OD_allmodes <- merge(OD_allmodes,
                     TO_census_21_DB_dt[, .(DB_UID, Population)],
                     by.x = "from_id", by.y = "DB_UID", all.x = TRUE)
 
OD_allmodes <- merge(OD_allmodes,
                     parkland_grouped_dt[, .(P_ID, area_ha)],
                     by = "P_ID", all.x = TRUE)
```

Checks, make sure these are 0 so we have no NA pop or areas. Good!
```{r}
OD_allmodes[is.na(Population), .N]
OD_allmodes[is.na(area_ha), .N]
```
For example, from DB 35200002001, 14.66667% of trips from this DB to any of the parks is assumed by car. The remaining comes from cycle (85.33333%)
```{r}
OD_allmodes |> filter(from_id == "35200002001" & mode == "Car")
OD_allmodes |> filter(from_id == "35200002001" & mode == "Bicycle")
```
Another example, from DB 35202920001, 37% of mode from this pop is assumed to travel by walk, 37% by car, and 0.18% by transit.
```{r}
OD_allmodes |> filter(mode == "Walk" & from_id == "35202920001")
OD_allmodes |> filter(mode == "Car" & from_id == "35202920001")
OD_allmodes |> filter(mode == "Transit" & from_id == "35202920001")
```

The populations that enter accessibility come from the TO_census. But let's confirm that this is correctly reflected in the OD_allmodes.
```{r}
sum_OD_allmodes_population <- OD_allmodes[, .(sum_O_i = first(Population) * first(prop)), by = .(from_id, mode)]

sum_OD_Walk_population <- OD_allmodes[mode == "Walk", 
                                      .(sum_O_i = first(Population) * first(prop)), 
                                      by = from_id]
sum_OD_Bicyle_population <- OD_allmodes[mode == "Bicycle", 
                                      .(sum_O_i = first(Population) * first(prop)), 
                                      by = from_id]
sum_OD_Transit_population <- OD_allmodes[mode == "Transit", 
                                      .(sum_O_i = first(Population) * first(prop)), 
                                      by = from_id]
sum_OD_Car_population <- OD_allmodes[mode == "Car", 
                                      .(sum_O_i = first(Population) * first(prop)), 
                                      by = from_id]
```


```{r}
TO_census_21_DB$Population|> sum() #the sum of pop from the DBs: 2794356

sum_OD_allmodes_population$sum_O_i|> sum() #2788293 (this object is by mode, so it produces the following four sums too...)
sum_OD_Walk_population$sum_O_i |> sum()  #881173.4
sum_OD_Bicyle_population$sum_O_i |> sum() #150163.4
sum_OD_Transit_population$sum_O_i |> sum() #501878.9
sum_OD_Car_population$sum_O_i |> sum() #1255078

sum(sum_OD_Walk_population$sum_O_i, sum_OD_Bicyle_population$sum_O_i, sum_OD_Transit_population$sum_O_i, sum_OD_Car_population$sum_O_i)
```


The first is the TOTAL population (2.79 mill~) -- and the others is the sum of pop that are going into the accessibility calculations (i.e., the sum of pop from DBs that reach at least 1 park (by park type)). It appears only slightly less (2788293) actually enters the accessibility calc from the perspective of market potential. Anyways, this is only ~6000 off, which is only 0.2%. I believe this is probably due to the prop rounding. 

## 2. Calc V_ij_0 and M_ji_0 for each m:

```{r}
access_allmodes <- OD_allmodes[, `:=`(V_ij_0_m = f * area_ha, #unconstrained access to parks
                   M_ji_0_m = f * Population * prop)] #unconstrained access to population
```

## 3. calc K^{mT} and \hat K^{mT} for the system:

```{r}
k_tot_allm <- sum_allmodes_PARKLAND/
  (sum(access_allmodes$V_ij_0_m))

khat_tot_allm <- sum_allmodes_POPULATION/
  (sum(access_allmodes$M_ji_0_m))
```

## 4. calc total constrained multimodal V and M

```{r}
access_allmodes2 <- access_allmodes[, `:=`
                                    (V_tot_ij_m = k_tot_allm*V_ij_0_m, #unconstrained access to parks
                                      M_tot_ji_m = khat_tot_allm*M_ji_0_m,
                                      kappa_tot_ij_m= V_ij_0_m/sum(access_allmodes$V_ij_0_m),
                                      kappahat_tot_ji_m= M_ji_0_m/sum(access_allmodes$M_ji_0_m)
                                      )] #unconstrained access to population
```

```{r}
access_allmodes2$V_tot_ij_m |> sum() #good, 8037.547
access_allmodes2$M_tot_ji_m |> sum() #good, 2788293

access_allmodes2$kappa_tot_ij_m |> sum()
access_allmodes2$kappahat_tot_ji_m |> sum() #should both be 1!
```


## 4. calc B_j and A_i multimodal
## 5. calc multimodal singly conc accessibility.

```{r}
B_j_m <- access_allmodes2[, .(B_j_m = if (sum(Population * prop * f) == 0) 0 else 1 / sum(Population * prop * f)), 
                          by = P_ID]

access_allmodes2 <- merge(access_allmodes2, B_j_m, by = "P_ID", all.x = TRUE)

access_allmodes2[, `:=`(
  V_opp_ij_m = B_j_m * Population * prop * area_ha * f,
  kappa_ij_m = B_j_m * Population * prop * f
)]
```

Checks, all flow ends (P_ID) should sum to that destination's opportunity number, and kappa should sum to 1. Nice! the total sum is 8037.547, the total hectres of area.
```{r}
access_allmodes2 |>
  group_by(P_ID) |>
  summarize(V_sum = sum(V_opp_ij_m), area_ha = first(area_ha),
              kappa_sum = sum(kappa_ij_m))

access_allmodes2$V_opp_ij_m |> sum()
```

Calculate the A_i_m:
```{r}
A_i_m <- access_allmodes2[, .(A_i_m = if (sum(area_ha * prop * f) == 0) 0 else 1 / sum(area_ha * prop * f)), 
                          by = from_id]

access_allmodes2 <- merge(access_allmodes2, A_i_m, by = "from_id", all.x = TRUE)

access_allmodes2[, `:=`(
  M_opp_ji_m = A_i_m * Population * prop * area_ha * f,
  kappahat_ji_m = A_i_m * area_ha * prop * f
)]
```

Checks, all flow beginnings (from_id) should sum to that origins population number, and kappa should sum to 1. Nice! All looks in order but the total sum is 2794356, the total population in the city. I was expecting to see ~6000 less, but that's okay- can't figure out why for now.
```{r}
access_allmodes2 |>
  group_by(from_id) |>
  summarize(M_sum = sum(M_opp_ji_m), Population = first(Population),
              kappahat_ji_m = sum(kappahat_ji_m))

access_allmodes2$M_opp_ji_m |> sum()
```
```{r}
TO_census_21_DB |> filter(Population != 0) |> nrow() #same number of rows included (i.e., unique dbs)
TO_census_21_DB |> filter(Population != 0) |> pull(Population) |> sum() #and the total number of population..? 
```

Save the megafile with all the accessibility flows:
```{r}
install.packages("fst")
library(fst)
write_fst(access_allmodes2, "./intermediate/access_allmodes.fst")
```

